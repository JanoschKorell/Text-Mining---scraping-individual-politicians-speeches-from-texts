{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2355b3b-1889-4bc0-9ce5-5e6085379582",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages')\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload')\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9')\n",
    "sys.path.append('/opt/local/lib/libgs')\n",
    "\n",
    "import sys\n",
    "if (sys.stdout.encoding is None):\n",
    "    print >> sys.stderr, \"please set python env PYTHONIOENCODING=UTF-8, example: export PYTHONIOENCODING=UTF-8, when write to stdout.\"\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import selenium\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import tabula\n",
    "import tabula.io\n",
    "import tabulate\n",
    "import PyPDF2\n",
    "import shutil\n",
    "import _tkinter\n",
    "import pandas as pd\n",
    "from scipy import nan\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import errno\n",
    "# import ghostscript\n",
    "import locale\n",
    "import warnings\n",
    "import xlrd\n",
    "import xlrd3\n",
    "from itertools import chain\n",
    "import functools\n",
    "import operator\n",
    "import pylab\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import tabula\n",
    "import tabula.io\n",
    "import tabulate\n",
    "import PyPDF2\n",
    "import _tkinter\n",
    "import pandas as pd\n",
    "from scipy import nan\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import errno\n",
    "# import ghostscript\n",
    "import locale\n",
    "import warnings\n",
    "import xlrd\n",
    "import xlrd3\n",
    "from itertools import chain\n",
    "import functools\n",
    "import operator\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pickle\n",
    "from io import StringIO\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tika import parser\n",
    "import json\n",
    "import pyperclip, re\n",
    "from itertools import chain\n",
    "import regex\n",
    "pd.options.mode.chained_assignment = None\n",
    "import collections\n",
    "from matplotlib.pyplot import figure\n",
    "import copy\n",
    "import pypdftk\n",
    "from PyPDF2 import PdfFileWriter,PdfFileReader\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "import mysql.connector\n",
    "import networkx as nx\n",
    "\n",
    "import itertools\n",
    "import click\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "import prince\n",
    "import seaborn as sns\n",
    "\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "#spacy.cli.download(\"de_core_news_sm\")\n",
    "#spacy.cli.download(\"de_core_news_md\")\n",
    "#from spacy.matcher import Matcher\n",
    "#from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from pathlib import Path\n",
    "#from spacy.tokens import Span\n",
    "\n",
    "#from spacy.symbols import ORTH\n",
    "#from spacy.language import Language\n",
    "\n",
    "#nlp = spacy.load(name='de_core_news_sm')\n",
    "\n",
    "#from Korrekturen_py import Korrekturen_py_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181a702-8db8-4d96-a60f-81d69e8135d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/janoschkorell/Desktop/Wissenschaft/Statistik/Python/Masterarbeit/Plenarprotokolle/Check/'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e37ac-7e42-4a47-a8be-a7f9da7b0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "\n",
    "def Check(filenamePDF):\n",
    "    gehnet_path = path + 'Check'\n",
    "    if not os.path.exists(gehnet_path):\n",
    "        try:\n",
    "            os.mkdir(gehnet_path)\n",
    "        except OSError as error:\n",
    "            if error.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    shutil.move(os.path.join(path, filenamePDF), gehnet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b56e0-05fe-4ba6-b65f-54ecd0db9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alle_docs = []\n",
    "fileNamePDF = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    \n",
    "        if \".pdf\" in file:\n",
    "            if \".txt\" not in file: \n",
    "\n",
    "                filenamePDF = os.path.basename(file)\n",
    "                print(filenamePDF)\n",
    "                data1 = parser.from_file(file)\n",
    "                stringAlle = data1['content']\n",
    "\n",
    "                pages_txt = []\n",
    "\n",
    "                #Read PDF file\n",
    "                data = parser.from_file(file, xmlContent=True)\n",
    "                xhtml_data = BeautifulSoup(data['content'])\n",
    "                z = 1\n",
    "                for i, content in enumerate(xhtml_data.find_all('div', attrs={'class': 'page'})):\n",
    "                    try:\n",
    "\n",
    "                        _buffer = StringIO()\n",
    "                        _buffer.write(str(content))\n",
    "                        parsed_content = parser.from_buffer(_buffer.getvalue())\n",
    "\n",
    "                        # Add pages\n",
    "                        text = parsed_content['content'].strip()\n",
    "                        text = re.sub(' \\n', '\\n', text).strip()\n",
    "                        text = re.sub('\\s\\n', '\\n', text).strip()\n",
    "                        text = re.sub(r'\\/', '', text).strip()\n",
    "                        text = re.sub(r'Dr\\. ', '', text,   flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'h. c. ', '', text,  flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'^\\(A\\)$', '', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'^\\(B\\)$', '', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'^\\(C\\)$', '', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'^\\(D\\)$', '', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'\\(Univ Kyiv\\) ', '', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'SPD9', 'SPD)', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'SPD\\n', 'SPD)\\n', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'SPD\\n', 'SPD)\\n', text, flags=re.DOTALL  | re.MULTILINE).strip()\n",
    "                        text = re.sub(r'([A-Za-zöäüéßğÖÄÜ]+) (Vizepräsident)', r'\\1\\n\\2', text)\n",
    "                        text = re.sub(r'1\\) Anlage 10', r'\\n\\n', text)\n",
    "                        text = re.sub(r'1\\) Anlage 2', r'\\n\\n', text)\n",
    "                        text = re.sub(r'1\\) Namensverzeichnis der Teilnehmer an der Wahl siehe Anlage 6', r'\\n\\n', text)\n",
    "                        text = re.sub('BÜNDNIS 90[\\nA-Za-zÜü \\-]+N', 'Grüne', text, flags=re.DOTALL | re.MULTILINE)\n",
    "                        text = re.sub(r'(\\d+)\\n\\n([A-ZÖÄÜ][a-zöäüéßèğ]+)', r'\\1\\n\\2', text) \n",
    "                        text =  text + '\\n\\n' \n",
    "                        text = re.sub('\\nDeutscher Bundestag\\s(\\-|\\–)\\s\\d+\\s?\\..*?\\n\\n', '\\n\\n', text,flags=re.DOTALL | re.MULTILINE)\n",
    "                        pages_txt.append(text) \n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                plenarpro = '\\n\\n'.join(str(e) for e in pages_txt) \n",
    "                alle_docs.append(plenarpro)\n",
    "\n",
    "                with open(filenamePDF+'_dirty.txt', 'w') as f:\n",
    "                    f.write(plenarpro)\n",
    "                fileNamePDF.append(filenamePDF)\n",
    "                \n",
    "                \n",
    "                \n",
    "df = pd.DataFrame()\n",
    "df.loc[:,'docs'] = alle_docs\n",
    "df.loc[:,'filenamePDF'] = fileNamePDF\n",
    "with open('df.pkl', 'wb') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbada1d3-66af-4c71-affa-b9f650a7de51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8b47c-cc9e-42bb-9676-e67104ae190a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Kernel3.9)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
